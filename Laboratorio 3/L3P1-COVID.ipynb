{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras_metrics\n",
    "import tensorflow as tf\n",
    "import shutil, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers, layers\n",
    "from tensorflow.keras import utils as k\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory,image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>offset</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>finding</th>\n",
       "      <th>survival</th>\n",
       "      <th>intubated</th>\n",
       "      <th>intubation_present</th>\n",
       "      <th>went_icu</th>\n",
       "      <th>in_icu</th>\n",
       "      <th>...</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>folder</th>\n",
       "      <th>filename</th>\n",
       "      <th>doi</th>\n",
       "      <th>url</th>\n",
       "      <th>license</th>\n",
       "      <th>clinical_notes</th>\n",
       "      <th>other_notes</th>\n",
       "      <th>Unnamed: 28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>65.0</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>January 22, 2020</td>\n",
       "      <td>Cho Ray Hospital, Ho Chi Minh City, Vietnam</td>\n",
       "      <td>images</td>\n",
       "      <td>auntminnie-a-2020_01_28_23_51_6665_2020_01_28_...</td>\n",
       "      <td>10.1056/nejmc2001272</td>\n",
       "      <td>https://www.nejm.org/doi/full/10.1056/NEJMc200...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On January 22, 2020, a 65-year-old man with a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientid  offset sex   age   finding survival intubated  \\\n",
       "0          2     0.0   M  65.0  COVID-19        Y       NaN   \n",
       "\n",
       "  intubation_present went_icu in_icu  ...              date  \\\n",
       "0                NaN      NaN    NaN  ...  January 22, 2020   \n",
       "\n",
       "                                      location  folder  \\\n",
       "0  Cho Ray Hospital, Ho Chi Minh City, Vietnam  images   \n",
       "\n",
       "                                            filename                   doi  \\\n",
       "0  auntminnie-a-2020_01_28_23_51_6665_2020_01_28_...  10.1056/nejmc2001272   \n",
       "\n",
       "                                                 url  license  \\\n",
       "0  https://www.nejm.org/doi/full/10.1056/NEJMc200...      NaN   \n",
       "\n",
       "                                      clinical_notes other_notes Unnamed: 28  \n",
       "0  On January 22, 2020, a 65-year-old man with a ...         NaN         NaN  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file= 'metadata.csv'\n",
    "dt=pd.read_csv(file, sep=\",\")\n",
    "\n",
    "dt.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver en que proporcion encontramos las muestras de covid y las de otras enfermedades para que la red no se sobre entrene con un solo tipo de imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co:  296\n",
      "Otro:  76\n",
      "Proporcion de Covid:  79.56989247311827\n"
     ]
    }
   ],
   "source": [
    "covid=[]\n",
    "otro=[]\n",
    "\n",
    "for i,r in dt.iterrows():\n",
    "    if r['finding'] == 'COVID-19':\n",
    "        covid.append(r)\n",
    "    else:\n",
    "        otro.append(r)\n",
    "\n",
    "print(\"Co: \",len(covid) )\n",
    "print(\"Otro: \",len(otro) )\n",
    "print(\"Proporcion de Covid: \", len(covid)/(len(covid)+len(otro))*100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que la funcion de keras: <i>image_dataset_from_directory</i> funcione para poder entrenar como queremos, separamos las fotos en dos capetas, una para covid y otra para el resto de enfermedades.\n",
    "\n",
    "Como hemos visto hay muchas más radiografias de covid que de las otras enfermedades así que vamos a igualar el numero de muestras para cada clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creamos los directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "carpeta = os.getcwd()+os.sep+'images'\n",
    "\n",
    "if not os.path.isdir(carpeta+os.sep+'covid') :\n",
    "    os.mkdir(carpeta+os.sep+'covid')\n",
    "if not os.path.isdir(carpeta+os.sep+'covid'+os.sep+'covid'):\n",
    "    os.mkdir(carpeta+os.sep+'covid'+os.sep+'covid')\n",
    "    \n",
    "if not os.path.isdir(carpeta+os.sep+'otro') :\n",
    "    os.mkdir(carpeta+os.sep+'otro')\n",
    "if not os.path.isdir(carpeta+os.sep+'otro'+os.sep+'otro'):\n",
    "    os.mkdir(carpeta+os.sep+'otro'+os.sep+'otro')\n",
    "        \n",
    "    \n",
    "\n",
    "if not os.path.isdir(os.getcwd()+os.sep+'perdidos') :\n",
    "    os.mkdir(os.getcwd()+os.sep+'perdidos')\n",
    "    if not os.path.isdir(os.getcwd()+os.sep+'perdidos'+os.sep+'covid'):\n",
    "        os.mkdir(os.getcwd()+os.sep+'perdidos'+os.sep+'covid')\n",
    "        if not os.path.isdir(os.getcwd()+os.sep+'perdidos'+os.sep+'otro'):\n",
    "            os.mkdir(os.getcwd()+os.sep+'perdidos'+os.sep+'otro')\n",
    "            \n",
    "            \n",
    "if not os.path.isdir(os.getcwd()+os.sep+'nuevas') :\n",
    "    os.mkdir(os.getcwd()+os.sep+'nuevas')\n",
    "    if not os.path.isdir(os.getcwd()+os.sep+'nuevas'+os.sep+'covid'):\n",
    "        os.mkdir(os.getcwd()+os.sep+'nuevas'+os.sep+'covid')\n",
    "        if not os.path.isdir(os.getcwd()+os.sep+'nuevas'+os.sep+'otro'):\n",
    "            os.mkdir(os.getcwd()+os.sep+'nuevas'+os.sep+'otro')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensiones=[1920,1500]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movemos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "foto=''\n",
    "destino=''\n",
    "ruta=carpeta+destino\n",
    "noEstanco=[]\n",
    "noEstanot=[]\n",
    "NombresEntrenoCo=[]\n",
    "NombresEntrenoOt=[]\n",
    "\n",
    "numcovid=0  #flag para equilibrar las muestras\n",
    "numvalco=0 #flag para coger muestras diferentes en prediccion covid\n",
    "numvalotro=0 #flag para coger muestras diferentes en prediccion otra enfermedad\n",
    "flag=0 #flag para no mover a las carpetas de images y que no aparezca en los dos directorios\n",
    "pacienteAnterior=0\n",
    "\n",
    "fotosCo=0\n",
    "fotosOt=0\n",
    "\n",
    "for i,r in dt.iterrows():\n",
    "    flag=0\n",
    "    foto=r['filename']\n",
    "    if r['finding'] == 'COVID-19': #si es covid\n",
    "        if numcovid<(len(otro)+10):\n",
    "            destino='covid'\n",
    "            numcovid+=1\n",
    "            \n",
    "        elif numvalco < 6 and r['patientid'] != pacienteAnterior: #ejemplos de covid para prediccion\n",
    "            if os.path.exists(ruta+os.sep+foto):\n",
    "                shutil.move(ruta+os.sep+foto,os.getcwd()+os.sep+'perdidos'+os.sep+'covid')\n",
    "                numvalco+=1\n",
    "                flag=1\n",
    "                noEstanco.append(foto)\n",
    "                \n",
    "    else: #Otra enfermedad\n",
    "        if numvalotro < 6 and r['patientid'] != pacienteAnterior:#ejemplos de  otra enfermedad para prediccion\n",
    "            if os.path.exists(ruta+os.sep+foto):\n",
    "                shutil.move(ruta+os.sep+foto,os.getcwd()+os.sep+'perdidos'+os.sep+'otro')\n",
    "                numvalotro+=1\n",
    "                flag=1\n",
    "                noEstanot.append(foto)\n",
    "        destino='otro'\n",
    "        \n",
    "    if os.path.exists(ruta+os.sep+foto) and flag!=1:\n",
    "        shutil.move(ruta+os.sep+foto,ruta+os.sep+destino+os.sep+destino)#+os.sep+destino\n",
    "        #para aumentar los datos\n",
    "        if destino=='covid':\n",
    "            fotosCo+=1\n",
    "        else:\n",
    "            fotosOt+=1\n",
    "    pacienteAnterior=r['patientid']\n",
    "    #print(ruta+os.sep+foto)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aumentamos la caantidad de muestras que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87 images belonging to 1 classes.\n",
      "Found 70 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aumento = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(dimensiones[0],dimensiones[1],3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.15),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.15),\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "nuevo=os.getcwd()+os.sep+'nuevas'\n",
    "df=image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1,shear_range=0.15, zoom_range=0.1,channel_shift_range = 10, horizontal_flip=True)\n",
    "#resul=image.DirectoryIterator(directory=carpeta, image_data_generator=df,target_size=(dimensiones[0],dimensiones[1]), color_mode='rgb', subset='training'\n",
    "#                        class_mode='binary',batch_size=5)\n",
    "#print(len(resul))\n",
    "#imagen=df.flow_from_directory(carpeta, target_size=(dimensiones[0],dimensiones[1]), save_to_dir=nuevo, save_prefix='Nuevas', classes=['covid', 'otro'],class_mode=\"binary\",batch_size=1, seed=1234)\n",
    "#save_prefix='Nuevas',save_format='jpeg',\n",
    "\n",
    "\n",
    "\n",
    "cov=image.DirectoryIterator(directory=carpeta+os.sep+'covid',image_data_generator=df,target_size=(dimensiones[0],dimensiones[1]), color_mode='rgb',\n",
    "                        class_mode=None,save_to_dir=nuevo+os.sep+'covid', save_prefix='Nuevas', batch_size=5,save_format='jpeg')\n",
    "otr=image.DirectoryIterator(directory=carpeta+os.sep+'otro',image_data_generator=df,target_size=(dimensiones[0],dimensiones[1]), color_mode='rgb',\n",
    "                        class_mode=None,save_to_dir=nuevo+os.sep+'otro', save_prefix='Nuevas', batch_size=5,save_format='jpeg')\n",
    "\n",
    "\n",
    "\n",
    "#imagen.next()\n",
    "#entreno=df.fit(imagen, rounds=4)\n",
    "\n",
    "\n",
    "#l=[]\n",
    "#for j in range(len(NombresEntrenoCo)):\n",
    "#    for i in range(9):\n",
    "#        #carpeta+os.sep+'covid'+os.sep+NombresEntrenoCo[j]\n",
    "#        imagen=image.load_img(carpeta+os.sep+'covid'+os.sep+NombresEntrenoCo[j], grayscale=False, color_mode='rgb', target_size=(dimensiones[0],dimensiones[1]))\n",
    "#        imagen=image.img_to_array(imagen)\n",
    "#        imagen=np.array([imagen])\n",
    "#        df.flow(imagen,batch_size=5, save_to_dir=os.getcwd()+os.sep+\"jk\", save_format='jpg',shuffle=True,save_prefix='Nuevas')\n",
    "        #nueva = aumento(imagen)\n",
    "        #cv2.imwrite(carpeta+os.sep+\"covid\",nueva[0].numpy().astype(\"uint8\"))\n",
    "\n",
    "#for j in range(len(NombresEntrenoOt)):\n",
    "#    \n",
    "#    imagen=image.load_img(carpeta+os.sep+'otro'+os.sep+'otro'+os.sep+NombresEntrenoCo[j], grayscale=False, color_mode='rgb', target_size=(dimensiones[0],dimensiones[1]))\n",
    "#    imagen=image.img_to_array(imagen)\n",
    "#    imagen=np.array(imagen)\n",
    "#    imagen.next()\n",
    "#    #image = np.expand_dims(ndimage.imread(carpeta+os.sep+'otro'+os.sep+'otro'+os.sep+NombresEntrenoCo[j]), 0)\n",
    "#    df.fit(imagen)\n",
    "#    for x, val in zip(df.flow(imagen,save_to_dir=os.getcwd()+os.sep+\"nuevas\"+os.sep+\"covid\",save_prefix='Nueva',save_format='jpeg'),range(5)):\n",
    "#        pass\n",
    "    #df.flow(imagen,batch_size=3, save_to_dir=carpeta+os.sep+'otro', save_format='jpg',shuffle=True)\n",
    "\n",
    "\n",
    "#df.fit(image)\n",
    "\n",
    "pd= layers.ZeroPadding2D(padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(cov))\n",
    "print(len(otr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    for i in range(len(cov)):\n",
    "        cov.next()\n",
    "    for i in range(len(otr)):\n",
    "        otr.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Guardamos las imagenes en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 717 files belonging to 2 classes.\n",
      "Using 646 files for training.\n",
      "Found 717 files belonging to 2 classes.\n",
      "Using 71 files for validation.\n",
      "Found 8 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#entreno, val, test=image_dataset_from_directory(directory=\"images\", image_size=(dimensiones[0],dimensiones[1]), subset=\"training\", validation_split=0.2, seed=1234,\n",
    "#                                      labels='inferred')\n",
    "\n",
    "\n",
    "\n",
    "#entrenamiento\n",
    "img_fit= image_dataset_from_directory(directory=nuevo, image_size=(dimensiones[0],dimensiones[1]), subset=\"training\", validation_split=0.1, seed=1234,\n",
    "                                      labels='inferred')\n",
    "\n",
    "\n",
    "clases=img_fit.class_names\n",
    "\n",
    "#validadcion\n",
    "img_val=image_dataset_from_directory(directory=nuevo, image_size=(dimensiones[0],dimensiones[1]),subset=\"validation\",validation_split=0.1, seed=1234,\n",
    "                                      labels='inferred')\n",
    "#clases=img_val.class_names\n",
    "\n",
    "#Prediccion\n",
    "img=image_dataset_from_directory(directory=\"perdidos\", image_size=(dimensiones[0],dimensiones[1]), \n",
    "                                      labels='inferred')\n",
    "\n",
    "#PARA MEJORAR EL RENDIMIENTO\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "img_fit=img_fit.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "img_val=img_val.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "Normalizar= layers.experimental.preprocessing.Rescaling(1./255, input_shape=(dimensiones[0],dimensiones[1], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREACION DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 1920, 1500, 3)     0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 1920, 1500, 3)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 1922, 1502, 16)    448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 640, 500, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 638, 498, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 212, 166, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 210, 164, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 70, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 68, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 22, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 20, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 6, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 4, 3, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 500)               256500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 1,829,769\n",
      "Trainable params: 1,829,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pool=3  #CON UN POOL MÁS GRANDE SE REDUCEN LOS PESOS\n",
    "model= Sequential([\n",
    "    aumento,\n",
    "    Normalizar,\n",
    "    pd,\n",
    "    layers.Conv2D(filters=16,kernel_size=3, strides=1,activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=pool),\n",
    "    layers.Conv2D(filters=32,kernel_size=3, strides=1,activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=pool),\n",
    "    #pd,\n",
    "    layers.Conv2D(filters=64,kernel_size=3, strides=1,activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=pool),\n",
    "    #pd,\n",
    "    layers.Conv2D(filters=128,kernel_size=3, strides=1,activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=pool),\n",
    "    #pd,\n",
    "    layers.Conv2D(filters=256,kernel_size=3, strides=1,activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=pool),\n",
    "    #pd,\n",
    "    layers.Conv2D(filters=512,kernel_size=3, strides=1,activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=pool),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Flatten(),\n",
    "    Dense(500,'relu'),\n",
    "    Dense(1,'sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/21 [>.............................] - ETA: 36:36 - loss: 0.0000e+00 - accuracy: 0.6562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-68c07bf24a3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopti\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistorico\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimg_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mvueltas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opti= optimizers.Adam(learning_rate=0.11)\n",
    "vueltas=10\n",
    "\n",
    "model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "historico=model.fit(img_fit, validation_data= img_val, epochs= vueltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESULTADOS DEL ENTRENAMIENTO SIN DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "acc = historico.history['accuracy']\n",
    "val_acc = historico.history['val_accuracy']\n",
    "\n",
    "loss = historico.history['loss']\n",
    "val_loss = historico.history['val_loss']\n",
    "\n",
    "epochs_range = range(vueltas)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================] - 66s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 70s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 70s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 70s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 70s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 69s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 70s 1s/step - loss: nan - accuracy: 0.5541 - val_loss: nan - val_accuracy: 0.5806\n"
     ]
    }
   ],
   "source": [
    "#Con los datos aumentados\n",
    "\n",
    "#historicoNu=model.fit(resul, validation_data= img_val, epochs=vueltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESULTADOS DEL ENTRENAMIENTO CON LAS NUEVAS IMAGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 files belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rutas=[ os.getcwd()+os.sep+'perdidos'+os.sep+'covid'+os.sep ,os.getcwd()+os.sep+'perdidos'+os.sep+'otro'+os.sep]\n",
    "#nombres=noEstanco+noEstanot\n",
    "#num=1\n",
    "#for i in range(len(rutas)):\n",
    "#    for j in range(len(nombres)):\n",
    "#        print(\"\\n\",nombres[j])\n",
    "#        if os.path.exists(rutas[i]+nombres[j]): \n",
    "#            \n",
    "#            image = tf.keras.preprocessing.image.load_img(rutas[i]+nombres[j], target_size=(dimensiones[0],dimensiones[1]))\n",
    "#            input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "#            input_arr = np.array([input_arr]) \n",
    "#            prediccion = model.predict(input_arr)\n",
    "#            \n",
    "#            score = tf.nn.sigmoid(prediccion[0])\n",
    "#            print(\n",
    "#                \"La radiografia numero \",num, \" pertenece a la clase {} con {:.2f} de precision.\"\n",
    "#                .format(clases[np.argmax(score)], 100 * np.max(score))\n",
    "#            )\n",
    "#        num+=1\n",
    "\n",
    "#Prediccion\n",
    "#img=image_dataset_from_directory(directory=\"perdidos\", image_size=(dimensiones[0],dimensiones[1]), \n",
    "                                      labels='inferred')\n",
    "model.predict(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: nan - accuracy: 0.2500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-533a68afeb87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistorico\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(img,verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
